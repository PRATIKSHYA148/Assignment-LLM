{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings Exploration\n",
    "\n",
    "This notebook demonstrates various word embedding techniques and their applications using popular libraries like Gensim and spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "# Download required NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load GloVe model\n",
    "glove_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Word Vector Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get vector for a word\n",
    "word = 'king'\n",
    "vector = glove_model[word]\n",
    "print(f\"Vector shape for '{word}': {vector.shape}\")\n",
    "\n",
    "# Find most similar words\n",
    "similar_words = glove_model.most_similar(word, topn=5)\n",
    "print(f\"\\nMost similar words to '{word}':\")\n",
    "for similar_word, similarity in similar_words:\n",
    "    print(f\"{similar_word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# King - Man + Woman = ?\n",
    "result = glove_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"King - Man + Woman = {result[0][0]}\")\n",
    "\n",
    "# More analogies\n",
    "analogies = [\n",
    "    (['king', 'woman'], ['man']),\n",
    "    (['paris', 'germany'], ['france']),\n",
    "    (['walked', 'running'], ['walk'])\n",
    "]\n",
    "\n",
    "for pos, neg in analogies:\n",
    "    result = glove_model.most_similar(positive=pos, negative=neg, topn=1)\n",
    "    print(f\"{' + '.join(pos)} - {' + '.join(neg)} = {result[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_word_embeddings(words, model, title):\n",
    "    # Get vectors for words\n",
    "    vectors = [model[word] for word in words]\n",
    "    \n",
    "    # Reduce dimensionality using t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    vectors_2d = tsne.fit_transform(vectors)\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], c='blue')\n",
    "    \n",
    "    # Add word labels\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, xy=(vectors_2d[i, 0], vectors_2d[i, 1]))\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example words to visualize\n",
    "words = ['king', 'queen', 'man', 'woman', 'boy', 'girl', 'prince', 'princess']\n",
    "plot_word_embeddings(words, glove_model, 'Word Embeddings Visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Custom Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample text for training\n",
    "sentences = [\n",
    "    ['the', 'king', 'ruled', 'the', 'kingdom', 'wisely'],\n",
    "    ['the', 'queen', 'governed', 'her', 'subjects', 'fairly'],\n",
    "    ['the', 'prince', 'learned', 'to', 'rule', 'the', 'land'],\n",
    "    ['the', 'princess', 'studied', 'the', 'art', 'of', 'governance']\n",
    "]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Find similar words\n",
    "print(\"Similar words to 'king':\")\n",
    "print(model.wv.most_similar('king'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing Different Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compare_embeddings(word, models):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        if name == 'spacy':\n",
    "            results[name] = [token.text for token in model(word).similar_by_vector(topn=5)]\n",
    "        else:\n",
    "            results[name] = [w for w, _ in model.most_similar(word, topn=5)]\n",
    "    return results\n",
    "\n",
    "# Compare models\n",
    "models = {\n",
    "    'glove': glove_model,\n",
    "    'spacy': nlp\n",
    "}\n",
    "\n",
    "word = 'king'\n",
    "comparison = compare_embeddings(word, models)\n",
    "\n",
    "print(f\"Similar words to '{word}' in different models:\")\n",
    "for model_name, similar_words in comparison.items():\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Word Embeddings Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Document similarity using word embeddings\n",
    "def document_similarity(doc1, doc2, model):\n",
    "    # Get document vectors\n",
    "    vec1 = np.mean([model[word] for word in doc1.split() if word in model], axis=0)\n",
    "    vec2 = np.mean([model[word] for word in doc2.split() if word in model], axis=0)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    return similarity\n",
    "\n",
    "# Example documents\n",
    "doc1 = \"The king ruled the kingdom wisely and fairly\"\n",
    "doc2 = \"The queen governed her subjects with wisdom and justice\"\n",
    "\n",
    "similarity = document_similarity(doc1, doc2, glove_model)\n",
    "print(f\"Document similarity: {similarity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
